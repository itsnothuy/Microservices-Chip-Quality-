# ü§ñ Coding Agent Instructions for Auto-Closing Issues

## üéØ **CRITICAL: Auto-Close Requirements**

To ensure your PR automatically closes the issue when merged to main, you **MUST** follow these requirements:

### ‚ö†Ô∏è **MANDATORY REQUIREMENT #1: Issue Reference**
**INCLUDE THIS EXACT FORMAT in your PR title or description:**

```markdown
Closes #005
```

Replace `#005` with the actual issue number. Use one of these keywords:
- `Closes #XXX` ‚úÖ **RECOMMENDED**
- `Fixes #XXX` ‚úÖ 
- `Resolves #XXX` ‚úÖ

### ‚ö†Ô∏è **MANDATORY REQUIREMENT #2: Quality Validation**
Your implementation must achieve **‚â•80% quality score** to auto-close.

---

## üìã **Complete Implementation Checklist**

### **Before Starting Implementation:**

#### ‚úÖ **Step 1: Read Issue Specification**
- Read the entire issue markdown file thoroughly
- Understand all acceptance criteria
- Review the implementation structure
- Check dependencies and references

#### ‚úÖ **Step 2: Use PR Template**
- Use the issue implementation PR template in `.github/PULL_REQUEST_TEMPLATE/issue-implementation.md`
- Fill in the issue reference: `Closes #XXX`

#### ‚úÖ **Step 3: Follow Project Conventions**
Follow the patterns in `.github/copilot-instructions.md`:

```python
# Type hints are MANDATORY
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, Field

# Use Pydantic models for validation
class InspectionCreate(BaseModel):
    lot_id: str = Field(..., min_length=1, max_length=100)
    chip_id: str = Field(..., min_length=1, max_length=100)
    
# Follow dependency injection pattern
async def create_inspection(
    request: InspectionCreate,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db_session)
) -> Inspection:
    pass

# Include comprehensive error handling
try:
    result = await service.create_inspection(request)
    return result
except ValidationError as e:
    raise HTTPException(status_code=422, detail=str(e))
```

### **During Implementation:**

#### ‚úÖ **File Structure Requirements**
Create **ALL** files specified in the issue implementation structure:

```python
# Example for Issue #005 (Event Streaming):
services/shared/events/
‚îú‚îÄ‚îÄ __init__.py                    # ‚ö†Ô∏è REQUIRED
‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # ‚ö†Ô∏è REQUIRED
‚îÇ   ‚îú‚îÄ‚îÄ manufacturing.avsc        # ‚ö†Ô∏è REQUIRED
‚îÇ   ‚îî‚îÄ‚îÄ inspection.avsc           # ‚ö†Ô∏è REQUIRED
‚îú‚îÄ‚îÄ producers/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # ‚ö†Ô∏è REQUIRED
‚îÇ   ‚îú‚îÄ‚îÄ base_producer.py          # ‚ö†Ô∏è REQUIRED
‚îÇ   ‚îî‚îÄ‚îÄ inspection_producer.py    # ‚ö†Ô∏è REQUIRED
```

#### ‚úÖ **Code Quality Requirements**
```python
# 1. ALWAYS include comprehensive type hints
def process_events(events: List[Dict[str, Any]]) -> Optional[ProcessingResult]:
    pass

# 2. ALWAYS include docstrings
def create_producer(topic: str) -> KafkaProducer:
    """
    Create a Kafka producer for the specified topic.
    
    Args:
        topic: Kafka topic name
        
    Returns:
        Configured Kafka producer instance
    """
    pass

# 3. ALWAYS include error handling
try:
    result = await kafka_producer.send(topic, message)
    return result
except KafkaError as e:
    logger.error(f"Failed to send message: {e}")
    raise ProcessingError(f"Message delivery failed: {e}")

# 4. ALWAYS use structured logging
import structlog
logger = structlog.get_logger()

logger.info(
    "event.published",
    topic=topic,
    event_type=event.type,
    correlation_id=event.correlation_id
)
```

#### ‚úÖ **Testing Requirements**
Create comprehensive tests with **‚â•95% coverage**:

```python
# Unit tests - REQUIRED
tests/unit/test_event_streaming.py

# Integration tests - REQUIRED  
tests/integration/test_kafka_integration.py

# Performance tests - REQUIRED
tests/performance/test_streaming_performance.py
```

#### ‚úÖ **API Implementation**
Follow OpenAPI specification exactly:

```python
from fastapi import APIRouter, Depends, HTTPException
from typing import List

router = APIRouter(prefix="/api/v1/events", tags=["events"])

@router.post("/publish", response_model=EventResponse)
async def publish_event(
    event: EventCreate,
    current_user: User = Depends(get_current_user)
) -> EventResponse:
    """Publish event to Kafka topic."""
    pass

@router.get("/topics", response_model=List[TopicInfo])
async def list_topics() -> List[TopicInfo]:
    """List available Kafka topics."""
    pass
```

### **Validation Prevention:**

#### ‚ùå **AVOID These Common Failures**

```python
# ‚ùå DON'T: Missing type hints
def process_data(data):
    return data

# ‚úÖ DO: Include type hints
def process_data(data: Dict[str, Any]) -> ProcessedData:
    return ProcessedData(**data)

# ‚ùå DON'T: Missing error handling  
result = await risky_operation()

# ‚úÖ DO: Comprehensive error handling
try:
    result = await risky_operation()
except SpecificError as e:
    logger.error(f"Operation failed: {e}")
    raise ServiceError(f"Processing failed: {e}")

# ‚ùå DON'T: Missing __init__.py files
# ‚úÖ DO: Include __init__.py in every package

# ‚ùå DON'T: Incorrect import paths
from models import User  # Wrong

# ‚úÖ DO: Use absolute imports
from services.shared.models import User  # Correct
```

---

## üéØ **Issue-Specific Implementation Guides**

### **For Issue #005: Event Streaming with Kafka**

#### **Core Requirements:**
1. **Kafka Integration**: Complete producer/consumer implementation
2. **Avro Schemas**: Schema definitions for all event types
3. **Event Publishing**: Reliable event publishing for platform activities
4. **Stream Processing**: Real-time analytics and processing
5. **Error Handling**: Dead letter queues and retry mechanisms

#### **Key Files to Implement:**
```python
# CRITICAL: These files MUST exist for validation to pass
services/shared/events/schemas/inspection.avsc
services/shared/events/producers/base_producer.py
services/shared/events/producers/inspection_producer.py
services/shared/events/consumers/analytics_consumer.py
services/shared/events/processors/stream_processor.py
services/event-processor/app/main.py
services/event-processor/app/routers/events.py
```

#### **Dependencies to Install:**
```toml
kafka-python = "^2.0.2"
confluent-kafka = "^2.3.0" 
avro = "^1.11.3"
fastavro = "^1.9.0"
```

### **For Issue #006: Observability & Monitoring**

#### **Core Requirements:**
1. **OpenTelemetry**: Distributed tracing implementation
2. **Prometheus Metrics**: Business and technical metrics
3. **Structured Logging**: Centralized logging with correlation IDs
4. **Health Checks**: Service and dependency monitoring
5. **Grafana Dashboards**: Real-time operational dashboards

#### **Key Files to Implement:**
```python
services/shared/observability/tracing/tracer.py
services/shared/observability/metrics/business_metrics.py
services/shared/observability/health/checks.py
monitoring/grafana/dashboards/quality.json
monitoring/prometheus/alerts/quality.yml
```

### **For Issue #007: Artifact Management**

#### **Core Requirements:**
1. **MinIO Integration**: Object storage for file management
2. **File Processing**: Image processing and metadata extraction
3. **Search & Discovery**: Full-text search capabilities
4. **Version Control**: File versioning and history
5. **Security**: Access control and virus scanning

### **For Issue #008: Quality Reporting & Analytics**

#### **Core Requirements:**
1. **Report Generation**: PDF/Excel report creation
2. **Statistical Analytics**: SPC charts and quality metrics
3. **Dashboard APIs**: Real-time dashboard data
4. **FDA Compliance**: 21 CFR Part 11 compliant reports
5. **Scheduled Reports**: Automated report generation

---

## üöÄ **PR Creation Checklist**

### **Before Creating PR:**

- [ ] All files from issue structure implemented
- [ ] Type hints added to all functions
- [ ] Error handling implemented
- [ ] Tests written with ‚â•95% coverage  
- [ ] Docstrings added to all public functions
- [ ] Import paths use absolute imports
- [ ] No syntax errors or Unicode characters in tests

### **When Creating PR:**

- [ ] Use issue implementation PR template
- [ ] Include `Closes #XXX` in title or description
- [ ] Fill out all template sections
- [ ] List all implemented acceptance criteria
- [ ] Document any design decisions

### **After Creating PR:**

- [ ] Verify GitHub Actions workflow runs
- [ ] Check validation passes with ‚â•80% score
- [ ] Respond to any validation failures
- [ ] Wait for auto-close after merge

---

## üîç **Troubleshooting Validation Failures**

### **Common Issues & Solutions:**

#### **Import Errors:**
```bash
# ‚ùå Error: ModuleNotFoundError: No module named 'database'
# ‚úÖ Fix: Use correct import path
from services.shared.database.base import BaseModel
```

#### **Missing Files:**
```bash
# ‚ùå Error: Missing required files: ['__init__.py', 'main.py']
# ‚úÖ Fix: Create all files from issue structure
```

#### **Test Failures:**
```bash
# ‚ùå Error: ImportError: No module named 'pytest_xdist'  
# ‚úÖ Fix: Already resolved in environment
```

#### **API Contract Errors:**
```bash
# ‚ùå Error: No FastAPI router found
# ‚úÖ Fix: Ensure routers are properly defined:

from fastapi import APIRouter
router = APIRouter()

@router.get("/health")
async def health_check():
    return {"status": "healthy"}
```

---

## üìû **Success Verification**

### **How to Verify Auto-Close Will Work:**

1. **Check Issue Reference:**
   ```bash
   # In PR title or description, verify you have:
   "Closes #005" or "Fixes #005" or "Resolves #005"
   ```

2. **Run Validation Locally:**
   ```bash
   source venv/bin/activate
   python tools/quality/validate-implementation.py \
     --issue issues/005-event-streaming-kafka.md \
     --output validation-005.json
   ```

3. **Verify Quality Score:**
   ```json
   {
     "quality_score": 85.0,  // Must be ‚â•80%
     "is_complete": true
   }
   ```

### **Expected Auto-Close Flow:**

1. **PR Created** ‚Üí Contains "Closes #005"
2. **PR Merged** ‚Üí Triggers auto-close workflow  
3. **Validation Runs** ‚Üí Checks quality score ‚â•80%
4. **Issue Closes** ‚Üí Automatically closes if validation passes

---

## ‚ö†Ô∏è **Final Reminders**

- **Issue Reference**: Must include `Closes #XXX`
- **Quality Score**: Must achieve ‚â•80%
- **File Structure**: Must match issue specification exactly
- **Type Hints**: Required on all functions
- **Error Handling**: Must be comprehensive
- **Tests**: Must achieve ‚â•95% coverage

**Follow these instructions exactly and your issue will auto-close successfully!** üéâ